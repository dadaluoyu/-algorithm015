毕业总结：
完整版请查看石墨文档地址：
https://shimo.im/docs/mWpCdKaoNYoSr1Xu/ 《毕业总结 算法训练营》，可复制链接后用石墨文档 App 或小程序打开
动态规划部分在notion上，地址：
https://www.notion.so/0a6f9c3a52534c2595045b16df2a623e
由于格式问题，以下只是内容预览，不方便阅读，后续内容会在石墨文档里更新。

——————————————————————

Git 版本控制流程
cd -algorithm015
cd Week_02
进到目录里

git pull origin master
取回远程的所有资源，在本地再在此基础上修改(如果远程没修改，可以省去这一步）
然后
写代码
git add .
添加全部进暂存区
提交
git commit -m "code"
git push -u origin master

极客大学的正确打开方式

极客大学算法训练营适合有一定算法基础的人去听，提炼、理解、提高，讲透本质
这些提纲挈领的去讲透了，再来看算法和数据结构，就是非常简单的东西了

70 天刻意练习，学会才是终点

不是看味道
2 倍速过一遍，难点反复看
摒弃旧习惯
职业化的训练
敢于死记硬背答案，你不熟悉，就要看职业选手怎么做
直接看国际版的高票回答，理解！

人生就是一场越狱
一定要成功

五毒神掌
死磕无法优化，因为你没看高手直播
打一把，就看一局高手直播，再看一把回放
过遍数

不要 AC 了事
每个题目至少做 5 遍，秒杀
五毒神掌重要的不是神，是五，过遍数
职业化训练方式、刻意练习

你学了那么多次，花了那么多钱，为什么没有拿下？
学习练习有误区


预习周：
预习课 1+覃超老师小课直播：课件先查看一遍
思考，回答问题

切题方法完成

职业顶尖水平，顶级互联网面试秒杀
Leetcode 300+熟练做题量

《异类》，马尔科姆

Chunk it up 切碎知识点
Deliberate practicing 刻意练习
feed back 反馈
他说的是对的，就是这样
投资也是，反复做，刻意练习

脑图，树状图，知识体系
Ask me everything——reddit，和名人提问对话


They sell themselves short without trying.
提早卖出了自己，没有继续尝试，没有意识到自己的潜力。
人是可以很强大的，相信自己

玩游戏的话也要做游戏的脑图，不能只是玩味道，大脑无法记住线性的知识
要找到一款好的脑图软件



跑赢人生长跑，跑出你自己的路
人生没有一劳永逸、一招制敌的解决方案，就算去了 FLAG 也不行
人生永远充满危机
稍有不慎，就难以为继
可能是你的身体，可能是工作，可能是家庭，可能是天灾人祸，谁也难说
时刻保持警惕，时刻准备着     

永远痛苦，永远有疑惑
永远迷茫
不要迷信知识，知识和能否成功之间没有强关系
要清楚很多都是无用功

资源占领、大招运营、团战战术、操作
位置、准度、找人速度，技能释放时机、团队资源分配
刻意练习

英雄在起起伏伏，但是游戏本质没有变

算法和游戏一样
你不能只是和同学一起无意识的打，玩玩味道，这样永远无法成为职业选手
你要做的是迭代、刻意练习
成功与否，和你投入时间的多少，其实没有强关联
时间是从侧面影响了更本质的东西
而那更本质的东西，才是决定我们投资成功和游戏高手的关键

和过往段位没有任何关系，拿个新号出来，有水平的自然有水平

要达到职业化的话，就要进行每一个区域的刻意练习

算法和数据结构：
简单化：

数据结构
三类：

一维：
基础：数组、链表
高级：  栈：先进后出
队列：先进先出
   双端队列 deque
   集合 set
   映射 map（hash 也是一种 map）

二维：
基础：树、图，是一维的泛化，加入分支
高级：BST（red-black tree、AVL）堆、并查集 disjoint set
  字典树 trie
高级是加入了特殊判断和约定条件的树

特殊：
 位运算、布隆过滤器
 LRU cache 和其他替换算法的 cache
主要是工程上的特殊应用

要逐步建立起自己的知识体系
算法
三种基础：和数学里的加减乘除一样基本
If else，switch——branch选择
For、while loop——Iteration迭代
递归 recursion、（divide & Conquer、backtrace 回溯）

最基本的语句
所有的数据结构和算法都会回归到这些语句

拆分复杂算法，找到重复单元，基于重复单元，就可以泛化成下面的高级数据结构

先拆再合，彻底理解算法


Mindnode 做的脑图

知道自己要学习的知识点是什么，还有知识点之间的关联是什么

作业：自己绘制脑图
理解和系统化

刻意练习
基本功是区别业余和职业选手的根本
基础动作的分解训练和反复练习

一遍是远远不够的
要变成条件反射
和背单词一样
过遍数
五毒神掌刷题

练习缺陷、弱点地方、自己找不舒服
不舒服、不爽、很枯燥，很好，你在进步，逐步突破瓶颈

真实世界的问题可能不是固定的，但正是习得了固定爆头、移动鼠标位置、击球的能力
才能有机会和基本功去应对真实世界的问题

高手的基本功都是很工整的
算法也是，典型题目过遍数，举一反三
克服误区
基础练习好了后，写工程就事半功倍了
先练后做

上班也是刻意练习！

反馈
即时反馈

主动式反馈：主动去找最佳实践
看 leetcode 题解

被动式反馈：
高手给你指点
Code review
教练看你打，给你反馈

切题四件套：

Clarification：和面试官沟通，看自己是否清楚题意
Possible solutions：写出所有的解法，分析时空复杂度，再从中找出最优的
Coding
Test cases：自己写一个测试样例跑一遍，让面试官看到程序是对的，他也就放心了
有始有终，我面字节就是差了这个部分，5 月份的时候，难受了

理解其意思，不要死板的死记硬背，没有抓住本质，也没用
要先速刷，再回顾重难点，反复看，吃透，再在练习中实践

背诵和默写，代码白板复现，能记住，重复多了，还是可以慢慢理解和学会的

不要减弱自己的积极性，能坚持是最好的
不能太挫败了，每段努力都要有积极正面的回报
所以速度一定不能太慢

最重要的是执行时间

五毒神掌：（我之前其实都错了相当于只做了第一次）
第一次抄写、理解题解
第二次马上再做
第三次第二天
第四次一周后
第五次面试前 1 周

肌肉式记忆
代码拍模板上去
要考的就那么多
中国学生学了这么多年，规范化的考试还不会吗？

https://pan.baidu.com/s/1rucC3q-9zD-lzs3yBkFU_g
（提取码：ykyn）

预习课 2：时间复杂度分析
训练环境设置，编码技巧和 coding style
环境设置
Mac：Iterm2 + zsh
google 已经弃用 eclipse 转向 IntelliJ 了
Python 就 PyCharm

右边标签分类可以专项练习
热度 100 的题目
专题讲解的题目
记得看国际站最高票的回答

要在实践中装好要用的软件，是最高效的配置方式，因为要用，所以配置
这是全世界最厉害程序员的思维结晶，学习先进生产力
这也是为什么要去阿里
接触最先进的生产力

没必要那么花哨，搞毛玻璃效果，不改变其本质

配置了 Pycharm 的 leetcode 插件
配置了字体 jetbrain mono 字体
配置了主题 monokai，真的漂亮

键盘设置速度拉满，让打字设备本身更 responsive，删除也会更快，这样的 mac 更好用，更适合 GEEK
边做边学，配合练习，这才是极客大学最好的打开方式

Codestyle：
google code style
所有的括号、关键字后面都要有空格
直接去看例子，他们是怎么写的，找出和自己不一样的地方，刻意练习

跟着覃超老师最高效的学习算法、工具使用
这门课的价值无限
绝对超值

学习的本质是什么？是为了解决问题、创造价值
为了锻炼你解决问题的能力
本质上还是要持续解决问题
如果公司的广告收益越来越高，就有钱招人、提高工资待遇什么的

五毒神掌第三遍第四遍，一定要去国际站上看看不同的顶级思维怎么考虑这个问题的
会对问题的本质有更深的理解

编码技巧
home 和 end 怎么用，是行头和行尾
fn + delete 删除光标后面的内容
cmd + left/right 去到行头、尾部
非常的好用
option + left/right 就是单词的切分
option + delete 整个单词的删除

以后不要一个一个移光标，更不需要用鼠标
一个成熟的程序员，是不需要用鼠标的，快捷键就可以完成所有的操作

shift + cmd + right（行首）/ left（行尾）  选中整行

把语句换位置，一定要非常的快捷
一定要优化到极致
简单事情重复做，经过优化后，就能产生巨大的价值

语句换位置，删除整句，都要熟练快捷键操作
mac 实在太牛逼了

选单词，跳整行
（好久没用 windows 了，mac 的 ios 是世界上最好的操作系统（linux））
程序员一定得用 mac，不管多贵都要买

Idea 的自动补全功能
option + 回车键，可以查询 IDEA 给你的修改建议，选中后回车就可以直接应用上去

psvm 直接打首字母，就会把 public static void main 打出来，非常的好用
caplock 轻触是切换输入法，非常的好用，没必要在 touch bar 上自找尴尬

cmd + E 在 IDEA 里面左右跳文件的操作
常用快捷键操作一定要刻意练习，搜 top tips，一个个去学会
一次学会，终身效率优化

做一题，得一题，重复、刻意练习
你会发现，编程，其实没有那么难
真的没有那么难

配置环境，软件使用，一定要刻意练习，比别人无意识的使用，更快，更有效率
自我迭代和刻意练习，就是我们进步的秘密
少做无用功
你学会了，再回过头来看同事，你就知道谁习惯好，谁习惯不好了
你就有了判断水平的标准了

工具不是普通的记事本，现代工具是如此的强大，一定要掌握几款世界上最通用、最有价值工具的使用方法，提高效率和生产力
而不能仅仅当一个记事本来用
工欲善其事，必先利其器

达到职业顶级水平

自顶向下的编程方式
clean code
newspaper metaphor 形式（类比）
头版头条在最前面，后面才是细节
最重要的在最前面，逻辑分明，框架齐全
而不要像散文，东一块西一块，不知道在干嘛

最关键的函数在最上面，私有的函数、细节逻辑的函数，就用子函数的形式，往文件或类的下面放
现代化语言，函数放在什么地方都可以，因为编译原理的逻辑更完善了
原来学 c 和 c++的时候，不放上面会出错
c 是几十年前的语言了，要接受现代化语言的便捷，也要学习经典语言的逻辑和特点，保持学习、不断进步

和面试官讨论 corner cases 的情况
仔细审题，弄清楚题目条件，不然出错了前功尽弃

以高层次，主干逻辑为主
lc125 验证回文串
filter out number & char
reverse & compare
思路非常清晰

String filtered_s = _filterNonNumberAndChar(s);
用大写字母来区分连续的单词分词
自顶向下，先关注实现逻辑和工程架构，架构设计好后，把函数列出来，不填里面的东西
真正跑通逻辑后再来专心的写子函数里的一个个代码，将大的问题分解成小的问题
再用模块化的编程手段去解决
不论是做算法还是做工程，都会高效不少
工程代码算法并不难，但是业务逻辑可能会比较复杂、模块比较多、有冗余（一层层下来）
你要代码写得快，bug 少的化
主要是先解决最上层的主干逻辑
代码可读性强，且不容易犯错
你觉得代码简单，可能不是因为你牛，而是写代码的人牛、可读性强
alphanumeric filter 用 google 搜一下，stackoverflow 上面就有一句话实现的代码
正则表达式
debug {
return s.replaceAll( regex:"[^A-Za-z0-9]", replacement:""); 
这里的 regex 和 replacement 是隐式的参数，是 IDEA 提醒你的参数
不需要打上来，你只把后面的参数元素内容打上来就行
然后不要拼错了！
}



写代码，永远只是一个初学者，永远在路上，向更厉害的人请教、学习、充实自己
成长，最重要的就是成长

其实我学习的方法是对的，不管进度如何，这都是我必须要学完的
不要为了短期完成任务的舒适感而放弃用长期主义的方法完整的做好这个事情
我不是为了完成任务，而是为了学习进步

Chrome ctrl + tab 就可以切换到下一个标签页了，非常的好用
ctrl + shift + tab 前一个标签页
cmd + tab 则是切换不同的桌面应用窗口
 
时间复杂度分析
直接看根据 n 的大小，这段代码会运行多少次

递归程序在执行时如何计算它的时间复杂度？
1.主定理
2.画递归树

网络流和归约的算法还是要好好复习一下

不同复杂度的问题，解决起来，耗费的资源完全不同

算法的时间复杂度优化后，对大规模的数据，提升是决定性的
简化，会减少很多成本

在寻找程序员这种最优秀的人才时，再怎么省都不能省程序员的钱
好的程序员创造出来的价值是惊人的
时间快，内存少

面试四件套：
1.确认无误题意
2.想所有可能解，比较时间空间复杂度
3.找出最优的解决方案
4.自己写一个样例，测试结果（靠谱）

全都做好了，怎么可能不过？

递归树、主定理 master theorem
我有点忘记具体内容和证明过程了

第 16 分钟的时候
http://stackoverflow.com/a/10597806
这里说得很清楚了
杨氏矩阵和 leetcode 74 不一样

杨氏矩阵在这里是 O(n)，每一列每一行都是递增的，但元素所在行和列之外没有大小关系，第二行第一个元素可能小于第一行最后一个元素。

如果是严格排序的矩阵，下一行的任意元素都大于上一行任意元素，就是 O(logn)

leetcode 74 做一下

树和图的节点遍历都是 O(n), n 是节点总数，访问一次且仅访问一次
BFS 和 DFS 是 O(n)
二分查找是 O(logn)

开了多少空间的数组
递归多少深度
他们的最大值就是空间复杂度（主导项的阶数决定一切）

为什么，递归树画出来，有多少层，每一层的节点数有限，递归结束后，就是 O(n)的
空间复杂度关心的是你需要的额外空间相对于原输入的级别
n 层就是 n 个类似原输入的数据量，耗费 O(n)的空间复杂度

输入数据量一般是一个数字
所以空间复杂度就是时间空间的 O 级别

记忆化搜索就是加一个内存

滚动数组就是常数级的内存，这种优化对于大数据来说是至关重要的
必须要优化到极致，才最省机器和运算资源

常用工具配置
基本功、编程指法（快捷键）的最佳实践（best practice）
要练熟



第一周：
第三课：数组、链表、跳表
基本实现和特性

python 数组是动态扩容的，高级很多
不用考虑数据量的问题了
现在的孩子们真的幸运，工具越来越好用

泛型

数组的优势：访问任何一个元素都是 O(1)
因为可通过内存管理器直接访问
知道下标后就行了，访问的依据是是首地址指针和下标偏移量
开一个数组，实际上是生成了数组首地址的指针

任何一个数据结构的关键就是增删查改
这和钢琴指法一样的，基本功一定要掌握好


增就是插入：O(n)平均移动一半的元素
删除也是，删除+移动，最后设置为空（触动 java 垃圾回收的机制）

Java 源码 arraylist
http://developer.classpath.org/doc/java/util/ArrayList-source.html
Java array list，是 java 在 array 上进行了一层封装
读源码，源码做的事情也没什么难的，很暴力，很简单，很工整
但不容易出错，很稳定

ensureCapacity 函数做了什么？
申请一个新数组，空间足够大，把老数组拷贝过去，返回新数组
mincapacity 不够的话，就 2*current 更大点，动态扩容
如果够的话，就 mincapacity 了

数组和链表的本质区别是在于访问元素的方式不同
链表里的 value 可以是一个类，成分可以很丰富，放很多数据进去
只有一个 next，单链表
前面有 prev，就是双向链表

tail.next = null
循环链表 tail.next = head

geekforgeeks，最简单链表实现，我没太懂每一部分元素的意思

CMU 15121 计算机基础课

用了 AnyType 泛型来指代节点

Java 里 T 是泛型
Linked list 是双向链表
first last，双向头尾

链表优势：
prepend 头节点增加
insert 
append 尾节点增加
插入 O(1)
删除 O(1)，删除后没有节点可以访问到它了，那么它就相当于从这个世界上消失了
我们人也是一样，需要有人能够访问到我们，建立连接

删除是插入的逆操作

访问是 O(n)的

没有完美的数据结构，array 和 linked list 各有优劣，并存
在逻辑上这两者的优势是矛盾的，不能并存的

优化：跳表

跳表必须有序，是对链表里有序元素进行的访问速度优化

跳表对标 AVL 平衡树 和 二分查找（用于有效查找有序数据中的元素）
平衡树比较早，跳表 90 年代出的，很晚
旧数据结构用 AVL 多，新数据结构用跳表比较多，比如 redis（服务器端缓存）

levelDB
google 最牛比的工程师，jeff dean 发明的

一维数据结构要加速，一般用的方法是升维
多一个维度后
就有多一级的信息在里面，带你超越一维的限制，从更高的维度超越进入

升维 + 空间换时间
这是很经典的算法优化思想，以后会反复用到的

跳表的本质是层级二分查找索引

一级索引，next.next
二级索引，跳一级索引的 next.next

基本上五级索引，小数据结构就够用了，多一倍的数据量就多一层索引
2^n 级别，索引层数永远远小于数据量

时间复杂度 logn
几级索引的个数就是 n/2 的几次方
最高级有 2 个节点，n /(2^h) = 2 那么 h = log2（n）-1

每层要遍历的元素，3 个
因为每级索引跨度都扩大了一倍，上一层有几个节点
下一层就每个节点旁边+1 个
要遍历的就是下一层头节点，+1，第二个头节点（因为上一层确定了范围，只能往下走，到底后就是查不到）

懂了懂了，彻底懂了，整个流程模拟了一遍

算法的本质是效率优化的理论上界

无论何时何地，优秀的算法人才都是最为紧缺的、有价无市的

跳表的维护成本更高，增加删除时间复杂度 logn
增加删除元素都要维护索引
会导致索引不平衡
越变动，跳表查找效率越低，类似于日松了

空间复杂度是 O(n)
就算隔 3 个跳索引，也是收敛
等比数列求和 1/k 总是小于 1 的

LRU cache leetcode146
skip list （redis）
redisbook.readthedocs.io

redis 源码比较复杂
你去看老师给的链接就行了

高级语言的数据结构都很好的封装了

跳表在并发加锁的时候，增删查改只涉及到索引局部性的改动
不会像 red black tree 一样对整个树 rebalance
并发性更好

高级数据结构面试时不会实现，而是理解为主，搞懂

第四课：栈、队列、优先队列、双端队列

栈：FILO，（等于 LIFO，是一个意思）查询为 O(n), 增删为 O(1)，因为只能从最上层开始增删
里面的元素是无序的，那么查询起来就需要把所有元素都遍历一遍

队列：FIFO
CRUD 时间复杂度和 stack 一样
create, read, update, delete

双端队列，deque
是栈和队列的结合体
头和尾都可以做元素的添加和删除

想了解实现，不要自己傻傻的模拟，去看看 Java 源码里的实现，Java 是开源的，代码又千锤百炼，是最佳实践了

如何查询接口信息，如何使用 deque 的 API？
授之以渔：如何查询自学

中文文档是有的，但是它讲得并不好，如果要追求代码的最佳实践，CS 的学习，就得去 FLAG 学
大部分都是代码，和语言关系不大

底层实现是什么？vector，和 arraylist 的区别是 vector 是线程安全的
官方推荐你在现实中用 deque 而不是 stack，因为 deque 更强大
不同的语言 API 都是不一样的，但大致类似，看官方文档就行了

java 里的 E 是 element
E 是元素的泛型，generics
元素不需要强制转换，更安全更通用，编译时会进行强类型检查
泛型让类和接口变成参数
泛型、类、接口、方法，这些都得好好学

compile-time error
run-time error
强类型检查的好处是，编译不通过，回头检查改 bug，总比运行时出错，找到不 bug 要好
提前发现问题，防患于未然，这些的都是编译原理方面的知识，非常值得一学

peek 是栈顶元素返回，pop 是不仅返回还弹出

为了稳定性会降一到两个版本

queue 是 interface 不是 class
接口接到它底层的很多 class 上，根据需要来使用
linkedlist
priorityqueue
delayqueue
线程安全：concurrentlinkedqueue
linkedblockingqueue
并发式的 concurrentlinkeddeque
arraydeque，用数组实现的双端队列

queue 提供了两组接口（方法组）
抛出异常 or 返回特殊值

add
remove
element 取元素不删除，和 peek 唯一的区别就是没有结果会抛异常

offer
pull
peek

函数是语句序列的打包；
方法是对 对象成员的操作，由函数实现；
接口是对方法的抽象和概括，由方法实现具体的接口

高级语言里数据结构一般是接口，实现有很多种，根据工程实际的需要来选择

concurrent 是类似并发的意思
blocking 是单线程的，多个线程访问会一个等一个
包括 non-blocking 都可以在并发式编程里面学习

deque 可以 first or last，接口种类多一倍
get 是得到 element 的

coding style: 左大括号前加一个空格，且不换行

queue offer 和 poll 不抛异常，只有返回值，里面没有元素，返回值为 null
remove 和 add 就会抛异常

在 deque 的方法里
addlast 比 push 要好
尽量用新的方法，都是经过千锤百炼优化过的

Stack<Integer>stack = new Stack<>();
stack.push(1);
stack.push(2);
stack.push(3);
stack.push(4);
System.out.println(stack);
System.out.println(stack.search(4));
stack.pop();
stack.pop();
Integer topElement = stack.peek();
System.out.println(topElement);
System.out.println("Position of 3" + stack.search(3));
/*
Queue
*/
Queue<String>queue = new Linkedlist<String>();
queue.offer("one");
queue.offer("two");
queue.offer("three");
queue.offer("four");
System.out.println(queue);
String.polledElement = queue.poll();
System.out.println(polledElement);
System.out.println(queue);
String.peekedElement = queue.peek();
System.out.println(peekedElement);
System.out.println(queue);
while(queue.size() > 0) {
    System.out.println(queue.pull());
}
/*
Deque
*/
Deque<String> deque = new Linkedlist<String>();
deque.offerlast("a");
deque.offerlast("b");
deque.offerlast("c");
System.out.println(deque);
String str = deque.peekFirst();
System.out.println(str);
System.out.println(deque);
while(deque.size() > 0) {
    System.out.println(deque.pollFirst());
}
System.out.println(deque);

priority queue 优先队列
是一种接口、一种抽象的数据结构
底层可以有多种具体的实现，看应用场景来选择
插入操作 O(1)
取出操作 O(logN), 按元素的优先级取出
取出变慢了，但是元素有了优先级

一般就是堆，取出最大值最小值的操作是 O(1)的，但是取完后要 heapify 花费 logn，而普通数据结构是 O(n)

底层具体实现的数据结构较为多样和复杂：heap、BST、treap
但是堆的具体实现也很复杂，不一定是基于二叉树形式的堆
可能是 Fibonacci 堆

二叉搜索树也能当 priority queue
也可能是 AVL 或者红黑树（平衡的二叉搜索树）

treap 是什么高级的数据结构？

用无序数组实现，插入 O(1), 取出操作比较慢，要 logn，quick select，比较级别，序
用实时排序的数组实现，插入的操作又比较慢，取出 O(1)，因为是优先队列，取出的是最高序元素
这里说得不太对，插入是 n + logn, logn 是二分查找位置插入，n 是移动整个数组，这才是对的
如果懒得自己写，直接 sort 整个数组，那就是 nlogn

priority queue 是一个 class
实现了接口 queue，所以 queue 的所有方法它都能用

priority queue 是优先级队列，里面的元素必须通过定义的 comparator 比较后得到优先级，没有优先级的元素不能进入队列（不可比较的元素不符合优先队列数据结构的规则）
也可以自己在参数中定义优先级字段

 public synchronized boolean empty() {
    return elementCount == 0;
 }
这也太优雅了，返回等式的结果，本身就包含了 true false，将计算阶段包含在 return 里，代码更简洁

Java 里面的 synchronized 是什么？ 同步？

stack 里面的 add、remove 这些基本方法，属于它的父类，Vector
Vector 想象成一个可变数组，学过 C++的更好理解

Stack 是先进后出，原来如此
stack 的 search 是什么意思？
懂了，pop 到第几个能找到目标元素

在 IDEA 里看源代码啊

modcount，记录数据结构的操作数，当操作数过高时，会有一些处理的措施、机制

element data 就是 vector 底层的一个数组
其实 vector 就是一种容器，container
高级数据结构的最底层的数据存储，要么在数组，要么在链表
高级的数据结构只是在增删查改上，根据不同的应用场景的需求，把性能 trade-off，达到所需场景的最优而已，类似空间换时间，用插入换搜索等等

len = s
新加入元素就先判断 size 够不够，不够就扩容
然后 直接 a[s] = element, 就行了
最后 len = s + 1

想要学透，一定得看源码，读源码就是在学习最高水平的代码，读艺术品一样，学到核心技术
java stack：
http://developer.classpath.org/doc/java/util/Stack-source.html
java queue：
http://fuseyism.com/classpath/doc/java/util/Queue-source.html
priority queue：
https://docs.oracle.com/javase/10/docs/api/java/util/PriorityQueue.html


删除数据结构里对应元素的底层操作
先判断边界条件，超 size 情况、小于 0 情况
然后把剩下的 index 后面的元素一次性 copy 到 index - 1 的位置，要删除的 index - 1 就自然消失了
最后一个元素设为 null
就可以让 Java 里的 GC，garbage collection 垃圾回收机制处理它

整个流程就授之以渔了，我知道怎么从网上看源代码这整个流程了
以后不管学什么语言都可以进去自己学

自己分析 queue 和 priority queue
python 检查错误和边界条件，它的鲁棒性比工业级的 java 要少很多
java 要考虑父类、子类、代码的复用等等，千锤百炼
类的结构会复杂很多

看 python 看得熟一点，因为我用的比较多
heapq，用 heap 实现的 priority queue
https://docs.python.org/2/library/heapq.html
python 提供了一个高性能的 container 库
https://docs.python.org/2/library/collections.html


www.bigocheatsheet.com

priority queue 是 BST 的时间复杂度


看不懂没关系，不要慌，再次遇到的时候，回过头来看就豁然开朗了
相当于埋了个伏笔
关键不在于记住细节，而是学会方法，以后遇到问题了可以自己去查，去学

Vector 不支持任意位置删除，只能通过迭代器删除，那什么是迭代器呢？
问题比较大，没有完全搞懂
那些博客是真的害人，水平不高，写得乱七八糟，一定要看官方文档，学系统性的课程知识
至少正确性和质量有保障
算法和数据结构还是没学透，底层还有一些不清楚的地方，可以加强

优先队列的时间复杂度，插入，取出（按优先级出来）
无序数组实现，插入肯定是 O(1)，取出是 logn 的，参考 quick select，单次快排过程丢一半处理
有序数组实现，取出肯定是 O(1)，插入是 logn 但是数组要移动，需要花费 n
堆实现，怎样都是 O(logn)

第二周
第五课：哈希表、映射、集合
除了数组链表之外，就是 map 和 set 了
映射和集合
底层结构使用 hash 表来实现（少量会用二叉树，属于特定情况）
hash：基础定义，特性
key value，关键码值
通过 hash function 映射到表中的一个位置（index) 来进行存储
缓存 LRU cache
Redis key value 对的存储

Java 里有 hash code 的方法，重载一下
哈希函数选的好，会让这些数值尽量分散，不会发生冲突的情况
hash collisions 哈希碰撞/冲突
区块链、比特币、大数据技术等等，都会用到大量的哈希
发生哈希冲突，可以再增加一个维度，在数组上发生冲突的位置拉出一个链表
拉链式解决冲突法
普通查询是 O(1)，但是遍历链表要 O(k), 效率会退化，k 是链表长度
这也是拉链式的一个缺点

但平均是 O(1)的，均摊时间复杂度，大部分情况是完美哈希的

C++的 STL、python 的库、java 的库、boost 库这些，内生就已经实现好了
原理搞懂一次，后续使用掌握使用方式即可

搜索 hash table java 10

时间复杂度因为现在的电脑内存都很大，可以认为非极端情况都是 O (1)，只有退化成链表赛爆了，才是 O(n)

自哈希表里抽象出来的，在 Java 里就是 map 和 set
map 对 python 就是 dict、dictionary 或者 json
set 就是 set

map 就是 key-value 对，key 不能重复，value 值可以重复
set 就是不重复元素的集合
new HashMap()/ new TreeMap()
map.set(key, value)
map.get(key)
map.has(key)
map.size()
map.clear()

new HashSet() / new TreeSet()
set.add(value)
set.delete(value)
set.hash(value)

python
list_x = [1, 2, 3, 4]
map_x = {
    'jack': 100,
    'sb': 100
}
set_x = {'jack','sb'}
set_y = set(['jack', 'sb'])

掌握了这些基本的工具，才能将问题模块化，引导到对应的功能上面去，从零开始构建信息世界

Oracle 还是做了很多事情的，Java，MySQL，这都是基础中的基础，下金蛋的鸡
Oracle 的 java 官方文档 set
https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/Set.html
map
https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/Map.html

set 只是一个 interface
treeset 是用二叉搜索树里的红黑树来实现的，查询 O（logn），是严格平衡的红黑树
而 hash 是 O (1)
基于并发 concurrent
enumset

查询元素是否存在：contains

Java 类里的 implement 是什么意思？
学 Java 看哪本书比较好？
上面还有 AbstractSet

Set 就是建立了一个 Hashmap
然后用 PRESENT 占了 value 的位置，所以有很多的冗余
PRESENT 是表示“我在场”的占位符，dummy value

看 hashmap 源代码：
只看两个函数就够了
put，主要是 putval
get，主要是 getnode

IDEA 下载源码下来看，很方便，可以直接查找跳转

第六课上：树、二叉树、二叉搜索树
树的本质：有多个 next 的链表，没有环的图
图的本质：图是树的超集，为了方便区分，把除了树之外的二维连接结构叫图，图是联通的，有环的，可以有向和无向，图的边可以带权值

链表是特殊化的树
树是特殊化的图

兄弟节点是 siblings


不同语言下 Tree 的实现
public class TreeNode{
    public int val;
    public TreeNode left, right;
    public TreeNode(int val){
        this.val = val;
        this.left = null;
        this.rigt = null;
    }
}

C++有点像基于指针的语言
struct TreeNode {
    int val;
    TreeNode *left;
    TreeNode *right;
    TreeNode(int x): val(x), left(NULL), right(NULL){}
}  

class TreeNode:
    def __init__(self, val):
        self.val = val
        self.left, self.right = None, None
为什么会出现树，本质是什么？

人类生活在三维世界、四维世界里，二维是对高维问题第一步的简化和抽象
是很自然出现的解决问题的一个方式，看待世界的一个切片的角度
很多问题的展开它本身就是树型结构的，一个问题包含几个子问题，子问题又包含几个子问题
递归的递归树

树的展开本质上是经过一步行为后问题状态的扩散
叶子节点就是问题的终局
终局思维，下棋下到不能再下的时候棋盘的状态
以终为始的思想，对大部分逻辑上状态有限（概率）的问题，如果知道棋盘的终局怎么样，这一步棋该怎么下，应该都很明了了
然而现实世界是无限游戏，多尾部事件，未来如何就算计算好了，也很难控制
要有理论的抽象，也要认清世界的真相

写算法，写软件，写功能，写框架，读书笔记，都可以很自然的画成树的结构，就是现在很火的思维导图

树状空间：状态树的空间
博弈空间：decision tree 的空间
这两个的复杂度决定游戏的复杂度
AlphaGo 做的就是在这个状态空间里找每一步决策的最优解
AlphaGo 和 AlphaZero 的论文读一下！
游戏也是一样，不过游戏里可以动的东西太多了
找到最优解

你的人生本身就是一棵树，星际穿越就是从高维度去干预节点
学算法的人，逻辑非常清晰、数学非常好

树的遍历
如果一个数据结构里面的元素都是无序的话，你查找一个数据，你就必须要遍历
其他顺序存储的数据结构就是循环一遍到遍历完毕
而树有左子树右子树
就需要递归去反复的求证（在不在左子树，在不在右子树，然后下一步这样，在每一个位置做的事情是一样的，操作是重复的、递归的）

根节点
左子树
右子树
这三种不同的状态都需要访问，左右子树在逻辑上是同构的，先左后右还是先右后左对遍历结果的性能没有区别，那么约定俗成先左后有，根的位置不同，三种组合方式就变成了三种遍历顺序

前序遍历，根左右
中序遍历，左根右
后序遍历，左右根
def preorder(self, root):
    if root:
        self.traverse_path.append(root.val)
        self.preorder(root.left)
        self.preorder(root.right)

def inorder(self, root):
    if root:
        self.inorder(root.left)
        self.traverse_path.append(root.val)
        self.inorder(root.right)

def postorder(self, root):
    if root:
        self.postorder(root.left)
        self.postorder(root.right)
        self.traverse_path.append(root.val)

树的定义本身很难进行有效的循环
而是通过递归这种方式来完成
数组是天然的循环结构，而树是天然的递归结构

强行用 BFS 循环，会很麻烦
不要怕去写递归，拥抱递归，递归是最符合本质的遍历方式
当一个方式很符合事物的本质时，它会很高效，很简洁，也很优美

二叉搜索树
普通的树，遍历还是 O(n)和链表没什么区别，没太大意义
只有将树里面的元素按照一定的规律有序化，才有性能的提升
不同数据结构的本质是根据需求进行性能的 trade-off 来达到使用场景下的最优

空树也是二叉搜索树，满足规则
规则：所有左子树的节点都小于根节点，所有右子树的节点都大于根节点（明白是 node 就行，就那意思），且所有左右子树满足规则本身（重复性）
中序遍历，左右根升序排列

查询和插入，普通的树是 O（n），因为你不知道末尾节点在哪，只能遍历到底部能插入的地方插入，这个过程就是 O(n)
而且树里面的元素无序，那树就不起作用了，普通的树状结构是没有任何效率的提升的，一定是有某种规则的应用，让整个树更高效了

而二叉搜索树是 O(logn) 相当于是加速了
为什么，因为本质是有序，有序就可以二分，二分就可以每次确定一半的不确定度
就可以 O(logn)，logn 的本质是和层数有关，每次只需要 1 次操作就可以进入到下一个阶段（子问题/子状态）
算法和数据结构就是这么简单

单链表的插入很快，就插入本身是 O(1)的，查询是 O(n)的
对于有序的数据结构，查询和插入往往是连在一起的，你得找准了位置再插

Morris 算法是什么？

遍历分两个过程，一个是经过，一个是返回值
经过不一定 return val，中序遍历左根右，虽然走右子树左边时经过右子树的根节点了，但会先返回右子树的左节点，理解这个顺序的产生原因，多看几遍动画模拟一下，实际的程序写起来才不会错

插入其实就是查找，你去查找这个元素，最后没找到的位置就是这个节点需要在的位置
BST 的插入和删除本质上不影响树里的其他结构，或者说本质上是局部的
这是一个很好的属性，当树足够大的时候，局部影响力意味着很小的操作损耗和较高的稳定性

删除一般是把右边最近的节点拉到被删除点的位置，其他部分保持不变即可
因为最近的一定是子节点，是右子树的最小值，最值一定在子节点上
所以其他节点的结构不需要变

为了避免 BST 退化成链表，效率由 O(logn)变 O(n)，会在操作后把它配平，变成平衡二叉
怎么实现的呢？下节课再讲

思考题：二叉树的面试题都是递归的，为什么？

第六课下：堆、二叉堆、图

堆：找最大值或最小值

优先级最高的任务，维护一堆数据，增加删除并能随时取出最值

用排序为什么不好？每次维护至少要 O(n), 插入多个数重排就是 nlogn 了（不可能业务里每次只插一个数，大部分是并行的）因为涉及到数组的重排和数组内存地址的移动、更新
而堆插入 k 个，klogn 就行了

二叉堆

斐波那契堆（工业级）
时空复杂度更好，基于树，多叉
做得好可以做到 O(1)insert

数组的删除会很耗复杂度，因为可能会移动近乎整个数组
升维
图灵奖选手，厉害了

堆是一种接口（数据结构的类别在实现上几乎都是一种接口）
有很多具体的实现

二叉堆的效率并不是最好的（相对容易实现），插入删除删除最值都是 logn，找最值是 O(1)
最好的是(严格的）Fibonacci 堆，插入删除、找最值都是 O(1)，只有删除最值是 O(logn)
实现起来比较复杂

如何实现

性质：
1.通过完全二叉树实现（前面全是有节点的，最后一层可以不满，但要依次靠左挨紧）
满二叉树就是满的

2.树中任意节点的值大于它的子节点的值（最小堆反之）
根节点是最值

做成树很方便
堆是通过数组实现的
完全二叉树都是数组
遍历子节点直接 2k+1，2k+2
父节点是 floor（(k-1)/2)
floor 是取整，向下取整，floor 5/2 = 2 

这是我在 EA 课上学到的

HeapifyUp
【插入】
如果大于父亲节点，就和父亲节点进行交换
复杂度 logn 只与层数有关，最多每层都交换一次

【二叉堆是相对有序的数据结构，抓大放小，局部层级有序，维护成本变小了，但是有序度也小了，查找其他元素不是那么方便，懂这个相关关系就行】

为什么可以层层交换，因为父亲节点一定大于所有的子节点，那么就没有必要和兄弟节点比较了，如果大，一定大，大小关系具有传递性

二叉搜索树和堆的区别是找最小值时 BST 要 O(logn)
优点是严格有序，可以找最大最小值什么的

HeapifyDown
【删除】

删除堆顶，然后取末位进顶部，从上到下
从上到下 heapify，和左右最大的儿子交换（大能保证调整次数最少，逻辑最优，最小堆反之即可），如果和小儿子交换，小儿子比大儿子小，又压着大儿子，辈分就更乱了，如果大儿子上来，一次调整就够了

归去来兮，有相似性，很精妙

复杂度都是 logn

堆是抽象的数据结构，表示一个功能，O(1)取最值，是一种接口，具体实现有不同的方式

工程里直接调用 priorit_queue 就行了

【源码讲解】
BinaryHeap

d = 2 分叉度

heap[heapSize++] = x；
相当于 x 放进去，再 heapsize ++
heapsize 是当前第一个可存储位置的指针

哦，这也太优化了
先把父亲节点的值赋回来
下标也更新
【数组操作，值和下标要同步更新】
while 循环完再赋自己的值到目标位置
厉害了
代码之美

private void heapifyUp(int i) {
        int insertValue = heap[i];
        while (i > 0 && insertValue > heap[parent(i)]) {
            heap[i] = heap[parent(i)];
            i = parent(i);
        }
        heap[i] = insertValue;
    }
基础代码功底一定要提高到极致
先保存要替换的值，记住它，然后位置迭代，到了目标位置再放入，一次搞定


【图】
图是抽象的数据结构，而具体实现是用邻接矩阵和邻接表
孤岛在图里也是合理的，符合业务逻辑

连通：直接连通 or 可到达
边：是否有向
权重：边的长度、损耗、费用
入度、出度，连接的边，是否有向
如果没有向，那入度=出度=连接边数

存储结构：
邻接矩阵：矩阵交叉处 0 代表不连通，数字代表权值
没有方向就是以主对角线对称的
有向就非对称了

邻接表：放直接相连的链表，存储 node.label node.val，邻接矩阵的列就是邻接表每一行的链表，数学上是一个东西
只是为了计算机存储、使用和维护的方便，用两种形式实现

无向无权
有向有权，四种图

常见算法：
高级算法在课后链接里自己去学，面试不考，我可以深入学一学，我其实学的已经很深了
算法功底再怎么好都不为过

DFS/BFS
树和图
图里 visited 集合一定要写，如果存在环路，没有 visited 判断，就会重复访问
而树天然没有环路，避免了这一点

visited 作为参数每次更新传入 dfs 函数，实时维护

DFS
递归：
递归终止条件
开始处理当前层
扩展节点
最后恢复本层的状态

代码模板一定要死记硬背下来，考试的时候不要思考，直接拍结果上去，完事，学霸流程
变成一种条件反射式的
花 5 分钟思考都是不能接受的
刻意练习，五毒神掌

visited = set()

def dfs(node, visited):
    if node in visited:
        return
    
    visited.add(node)
    process(node)    

    for next_node in node.children():
        if not next_node in visited:
            dfs(next_node, visited)

def BFS(graph, start, end):
    queue = []
    queue.append([start])
    
    visited = set()
    
    while queue:
        node = queue.pop()
        visited.add(node)
        
        process(node)
        nodes = generate_related_nodes(node)
        queue.push(nodes)

 numbers of islands

连通图个数： https://leetcode-cn.com/problems/number-of-islands/ 

拓扑排序（Topological Sorting）： https://zhuanlan.zhihu.com/p/34871092 
 
最短路径（Shortest Path）：Dijkstra  https://www.bilibili.com/video/av25829980?from=search&seid=13391343514095937158 

最小生成树（Minimum Spanning Tree）： https://www.bilibili.com/video/av84820276?from=search&seid=17476598104352152051 

看懂后在 git 上下载代码，然后自己修改一下工程实现，这样子
这就是搬砖，不要自己造轮子

第三周：

第七课：泛型递归、树的递归
树一般是用递归来解题的

1.定义是根据递归来定的
2.定义数据结构和算法时具有重复性、自相似性

通过函数体实现，本身就是一种循环
递归和循环没有明显的边界，解决生活中的重复性
递归——通过函数来调用自己进行循环
汇编语言里是函数语句位置的重复跳转

递归很像 inception 盗梦空间
1.只能一层层上去再一层层返回，不能跳层，具有对称性
2.函数的参数层层传递，通过参数实现函数不同层之间的传递变量
3.但函数里的环境变量保持在该层互不影响，每一层的环境和周围的人都是一份拷贝

求 n 的阶乘
def fac(n):
if n <= 1:
return 1
return n * fac(n - 1)

带函数进下一层，然后到最底层返回结果，再一层层把结果向上传得到返回值
递归调用的时候，系统给我们做了一个调用栈

尾递归？

// Java
public void recur(int level, int param) { 

  // terminator 
  if (level > MAX_LEVEL) { 
    // process result 
    return; 
  }

  // process current logic 
  process(level, param); 

  // drill down 
  recur( level: level + 1, newParam); 

  // restore current status 
 
}

def  recursion(level, param1, para2, ...):
    if level > MAX_LEVEL:
        process_result
        return
    #recursion terminator 递归终结条件    

    #process logic in current level 处理当前层逻辑
    process(level, data, ...)
    
    #drill down 下探到下一层
    self.recursion(level + 1, p1, ...)
    
    # reverse the current level status if needed 恢复当前层状态    
递归四步，如上

思维要点：
1.不要再进行人肉递归了，直接看函数本身开始写，四步函数逻辑是正确的就够了
你能理解是怎样一个框架过程就行了，细节交给计算机去算，结果是对的就行
否则你永远无法熟练使用递归，因为人肉依赖了，人肉的算力只能算出很简单的递归
后面的递归可能会比较复杂

2.找最近最简的方法，将其拆解成可重复解决的问题（重复子问题）
复杂的问题能用递归解决，本质原因是算法逻辑具有可重复性

3.数学归纳法
最简单的条件成立，且你能证明 n 成立时 n + 1 成立

第八课：分治、回溯
分治和回溯本质是递归，一种特殊形式而已

碰到这类题目就找重复性，最近重复性（分治、回溯等等），最优重复性（动态规划）

分治
基本上递归就需要分治，一个问题有很多个子问题，递归求解，就是一种分治法
只有一个子问题的题不需要分治，特例吧，比如求阶乘
不这么乘（一个问题嵌套几个子问题）也不需要递归，也没那么复杂了

找重复性
能分解成子问题
分治解决

这一类问题能用计算机快速解决，本质是重复性
找到本质是关键，背书上的内容毫无意义
学懂，会用才是关键

这类问题本质上就是找重复性以及分解问题
最后组合每个子问题的结果

为什么这么解决？语言的结构就是顺序读取执行跳转重复的
硬件限制运算只符合这一类规则
能找到重复性的问题基本都是计算机可解的
变成重复性的不断的反复和迭代

分治代码模板

递归四步的基础上，在倒数第二步插一步
这一步：组合每个子问题的结果
分治需要对中间结果进行处理和保存

terminate 的条件
子问题 is None / 子节点 is None

要点
1.怎样拆分成子问题比较重要，主要看经验
CEO 或者是架构师要完成的事情
2.怎样 merge subresult 很重要
3.子结果如何做质量控制和质量保证（尤其是子结果较多时）
下面的人给你一个结果，你怎么快速的知道他做得好还是不好？
根据子结果的好坏给予相应的激励，这就是一个公司的组织文化、结构

和自顶向下的编程思想一致
当前层你只要考虑当前层的问题
一般来说不要下探，或者至少不要下探太多
因为人脑不太适合人肉递归，层数很小
而且一竿子插下去，你不了解细节，这种微管理很讨厌，事倍功半

程序也如此

回溯

理解了思想，算法其实很简单
八皇后问题就是典型的回溯法
一层层，一个个去试
不行就返回来走上一层的下一个结果，看看行不行

一直往下走，直到走不通，返回上一层，跳到下一步，继续往下走
越早剪枝，越可以节省你的执行次数/时间
数独也用回溯法解决

LC22 括号生成
左右括号数量匹配
最外层一定是左括号和右括号

power （x，n)
这题目也值得做一做

位运算，八皇后的终极解法
八皇后算是高中生平均编程水平的巅峰了，再往上就太难了，我是学到八皇后就不会了
或者说练少了，不会五毒神掌，边写边忘，不熟

先做题，再看解题视频，然后再做一遍题，顺序一定要对


第四周：
第九课：深度优先搜索和广度优先搜
搜索：暴力搜索，无重复遍历整个空间
访问一次且仅访问一次
访问顺序，按优先级优先访问，最常见的是深度优先和广度优先
优先级优先在现实生活中用的比较多，一般叫启发式搜索（A*的优先级就是距离远近）
估价函数和搜索的效率，是深度学习的，超出了这门课的范畴了
优先级优先用于推荐算法，让你搜索出你最感兴趣的东西
粗排精排都是优先级搜索
推荐也是优先级推荐，只不过大厂的估价函数很复杂


DFS的路径遍历顺序就是递归的递归树生成的顺序
两者结构一样，本质上是一个东西
不等循环走完就展开下一层，返回上一层时看上一层有没有其他儿子，有就进去，没有就继续向上返回

图的话是遇到遍历过的节点就返回
判断是否遍历过，可以加在第一句，和递归终止条件的结构保持一致

懂了懂了，图的遍历要判断是否访问过，而树不要
树天然不会重复访问

#非递归写法
#Python
def DFS(self, tree): 

    if tree.root is None: 
        return [] 

    visited, stack = [], [tree.root]

    while stack: 
        node = stack.pop() 
        visited.add(node)

        process (node) 
        nodes = generate_related_nodes(node) 
        stack.push(nodes) 

    # other processing work 
    ...

就是手动pop，push模拟系统的栈

BFS
用队列遍历
找到就是最优，因为层次遍历，当前层是理论最小层，因为前进到当前层是没找到，找到了，就不会继续前进
而深度优先还不好说

# Python
def BFS(graph, start, end):
    visited = set()
    queue = [] 
    queue.append([start]) 

    while queue: 
        node = queue.pop() 
        visited.add(node)

        process(node) 
        nodes = generate_related_nodes(node) 
        queue.push(nodes)

    # other processing work 
    ...
因为队列天生按顺序进出，层次遍历，上一层总是先出来被处理

注意要visited
因为处理相连节点，需要标记，避免重复处理

BFS天生是非递归的，因为层间没有重复性，队列进出就可以天然层次遍历，不然在递归里不同层还要区分，无法用同一种方式重复表达
DFS非递归写法就是用stack代替BFS里的queue，其他部分都是一样的
DFS用递归是系统能帮你自动维护一个栈，因为程序的调用就是基于栈的
而广度优先是要手动维护的，和非递归DFS一样

DFS、BFS都是遍历算法，把所有节点都访问一遍

只有重要的东西会重复出现，笔记不用事无巨细，你有可能用不到，真正理解是关键
五毒神掌做实践应用
模板一定要懂，掌握熟

整个 DFS 和 BFS 的过程，理解后就非常简单，这只是基础而已

第十课：贪心算法
贪心算法与动态规划的区别是贪心只会记录局部最优，而动态规划保存以前的运算结果
根据以前结果对当前结果进行选择，可以回退

局限性：
什么时候可以用贪心，或者说在哪一步可以用贪心，达到全局最优？

贪心 = 当下做局部最优判断
回溯 = 没找到答案就回退
动态规划 = 带最优判断的回溯 = 贪心 + 回溯

特定的最优化问题：最小生成树，哈夫曼编码
一旦一个问题能被贪心法解决，那么一般贪心法是解决这个问题的最好办法（正确性，有效性、最优性、复杂度？）因为简单，如果适用，那么就是高效


贪心法可以作为辅助算法，先求一个模糊近优解，或者直接完成一些算法的中间步骤

为什么贪心法是正确的，就是前面的选项如果被选，一定比后面的选项更优
选项比较级的传递性是一致的
用术语来说，这种子问题的最优解就是最优子结构
能把问题分解成子问题，子问题的最优解能递推到最终问题的最优解

贪心法的难就难在你怎么证明它是可以用贪心法的
【是很难做的，搞不懂，很难判断的，可以先试一下，能贪心就贪心，不能再想别的方向】
以及贪心的角度不一样
有些时候可以正常的用贪心，有些时候必须把问题稍微转化一下
从前往后贪心，还是从后往前贪心


分发饼干，把大饼干分给小胃口不会比把大饼干分给大胃口更好
贪心法就行了

贪心法一旦可用，算法复杂度一定是最优的
因为可以抛掉所有的次优解、中间结果
也不需要遍历全部状态，用分治回溯等等

贪心追求短期利益
无法接受短期痛苦但是长期受益的事情

买卖股票的最佳时机
这一系列都可以动态规划，状态转移方程不同，学会怎么写
贪心算法很难想，但一定是最优的，而且很简单
这一系列第一题贪心很简单，但是你往后做透了，就会对动态规划有新的体会
算法是程序员的基石

从后往前贪心，或者从某一个局部切入贪心

为什么是贪心，因为省略了中间状态，只用记录当前状态的最值
一定是最优的
贪心法很精妙，一旦可用，就直指问题本质
O(n)





你记录题目的代码，是个好习惯，但也别太在意
先全部放到 git 上，有需要再查
你把好的笔记都记下来吧
认真开始刷题，我之前没记笔记，是因为刷的都不认真

算法和数据结构一定要学到极致，学到A+

第十一课：二分查找

二分查找的前提：
1.目标函数的单调性（有序的）
2.存在上下界，bounded
3.能够通过索引访问 index accessible
（单链表不行，跳表可以，跳表具有数组性）
# Python
left, right = 0, len(array) - 1 
while left <= right: 
      mid = (left + right) / 2 
      if array[mid] == target: 
            # find the target!! 
            break or return result 
      elif array[mid] < target: 
            left = mid + 1 
      else: 
            right = mid - 1

实数情况不是+1 -1，直接等于mid就行
搞懂本质了，就都能理解了
二分法我擅长的

二叉搜索树BST是天然二分的，而二分法是靠数组的有序性和索引访问完成的
本质都是一样的，减少一半的不确定性

可惜在哥大还没有学透，要是学透就好了，十一回去查查考试资料，复习一下

多个地方的模板比对分析
递归模板
二分模板
动态规划模板
分治回溯模板

关键是代码写熟，bug free
先把代码模板拍上去
再微调中间的值，再调边界条件
确保bug free

不是看你是不是非常快的写到最精确的代码
而是看你在写代码的过程中思维逻辑是否清晰
DEBUG能力是否强，我面字节的时候，debug能力确实差了点，连自己的测试用例都写不出来
以后要离开各种参考资料，白板写题，把期中考试的两道题都写对

面试时说可以用一个算法的时候，先要回答为什么要用这个算法
真正关键的不是你的相框，而是你的实力

为什么sqrt可以用二分查找？
因为x^2, x大于零，函数曲线在y轴右侧单调递增且连续
且它有一个上下界（答案的上下界）最小是0，最大是x
答案一定在其中

上下界，就是left, right
为了避免相加除以二越界，优化成left + (right - left)/2，这是性能优化

牛顿迭代法
真的很简单，新的战术体系解决原来的方法
雷神之锤3的引擎
平方根之一
在3D引擎里面，涉及到矩阵变换，用的非常多
因为你求两点之间距离就是（x平方+y平方），再开根号

这里有一个magic number，是通过经验得到的

John Carmack是雷神之锤创始人，现在在Oculus
在特定问题里用牛顿迭代法而不是二分，作为业界的最佳实践
最优应该是针对问题特异化的数学方法，而不是通用算法
优化到理论的极致

牛顿迭代法：以直线代替曲线，用一阶泰勒展开式（即在当前点的切线）代替原曲线，求直线与x轴的交点，重复这个过程直到收敛。

懂了懂了，彻底懂了牛顿迭代法，太简单了，一个方法而已
x0怎么选的？

对于x^2 - a = 0, 求x值的迭代公式是1/2 *（当前值+x/当前值）
写程序只需要写这个迭代公式就好了

有很多人的代码写得并不好，要优化到极致
不同时间段的代码有不同的进步，越来越好，越来越懂

15分半这里，牛顿迭代法，如果r = x 不是完全平方数，在while循环里会死循环，因为 r*r永远大于x，必须设立一个终止条件，比如if r*r - x < 1e-6: break， 或者直接//整除，否则会报错。

lc国际站牛人：StefanPochmann
代码写得一直都很好，很简洁
还要tourist！

牛人的代码也会有瑕疵，要有自己独立的思考能力
取其精华，弃其糟粕
比如对其没对好，这是coding style的问题

看到一半了，还有第二题和hw题没做，下次继续做一做

五毒神掌刷题
四步切题做题
审题：细节、边界条件、输入输出的范围、阴险输入情况等，说清楚
所有解法都思考一遍，相应时空复杂度求出来，得到一个最优解，在面试官同意的情况下，用最优解法写代码
写代码
自己写一个测试样例，证明能跑通，你要给正常的测试、边界条件、变态情况、错误的输入，你都要证明你的程序能跑

没有过面试是能力不够，你要懂啊
加油，会进步的，等我能力上去后，想去哪都行

思路：1.二分查找找突变点，还原后，二分查找找答案
2.直接二分查找

二分查找条件：有序、边界、index
虽然不是严格有序，但是具有一定的单调性

二分法：就把它当成二分查找，硬上就行了，左右两种情况缩，分类
暴力法：两次二分，第一次二分找中间点，第二次二分找值
你多看几次，会豁然开朗
慢慢的就学会了

作业题LC 74
搜索二维数组，两种方法
1.变成一维数组去查找
2.左下角或者右上角线性查找

第五周：期中考试

直播

jim simons

不是连续怎么办?把所有正数拿出来就行了
面试肯定都是原题，不会难为人的

做到300题再去举一反三

每天大于3题是起码的要求


可以只看一遍，把自己的脑图做起来
挡住，再复习一遍

同样的数据元素，链表比数组存储空间消耗大，因为有next指针

注意算法里的n是什么具体含义，能不能归约
复杂度和复杂度不一样

时间复杂度怎么分析

如何1分钟快速分析

其实就是MN
没有来到wordlist的单词就会出现
进去的单词只是wordlist里的单词，只会出现一次
queue里只进去一次
循环是O（m）我太急了，没有看对

对每一个单词书里的词遍历一次

展开啊，应该是n平方

2的N次方

看两个string是否match

递归了，分支调用1次或2次ismatch，s -1 或者 p - 2，如果分2个最坏情况，就递归了
第二种分支长度都会减1，跑一次

最坏情况下一分为二，-1 -2都无所谓了，n层，2的n次方

大部分递归调用都是2的n次方

递归不可能出现n平方
只有循环才会是n平方


106代码
132 657 4
123 4 567
从中序和后序遍历得到二叉树

后序左右根
中序左根右

4是根
4左边左子树，右边是右子树

1 2是根 3

同理可得，递归
2是根



链表判断有没有环？
1.哈希表缓存

2.快慢指针
拓扑排序不行，因为没有办法有效拓扑排序，图可能无方向
labuladong有双指针判断链表有没有环的方法

快慢指针找第k个元素，快指针先走k步，之后慢指针一起，慢指针就是答案

左右指针三数之和
你不一定能找到，你找到边界就行了，可解

合并两个链表，这个是正确的，只要把指针别过来就行了，只需要指一次，其他的不用管


谁小就以谁为头

lc 88 合并两个有序数组，高频题，没什么好说的


从后面开始放，放前面就没有位置了，哪个大就选谁，慢慢放

python API是真的好，简洁，做题太快了

我差的还有点多


头条第三面压轴题
LC 23 合并K个有序链表

定义优先队列，有比较的方法
然后把所有链表的头节点，加在优先队列里
然后每次从优先队列里拿最小值
在前面的next赋值
p.next就是取出来的queue的最小值
把较小的值的next加到优先队列里继续比较

代码放在脑图里，平时多看

期中复习回顾一遍


lc 75 颜色分类
把零放最左边，2放最右边
荷兰国旗问题


你可以排序，可以count计数，可以双下标
左边指针是0的边界，l++，右边指针是2的边界， r--

如果是0，放到左边界，l++，如果是2，放到右边的边界，r--
判断代码是否正确，代一个最简单的例子进去算就行了

为什么要i --？这里没怎么懂


因为有一个元素没有判，i那个位置没有判断， ++i后回到i，再判断一遍


正确了，nice

数组的下标一定要掌握好

继续加油
好好记忆理解，比新的算法更重要，不然永远没学
做一题，得一题

首先要sort一遍，不然不能用双指针去夹逼
为什么len - 2

只要在k的后面用双指针

k + 1 和 len - 1
双指针去夹

这是双指针夹逼的代码块


while循环判重
非常关键

++i
--j

这种形态特别精妙


这种比较好理解
++l 就是先



第一个条件判断是不可能等于0了
第二个条件是nums[k]被验证过了，就不重复做了

判重并不简单
哈希表判重更是大麻烦的事情


这个c++写的真的好


先是越做越厚，再是越做越薄



跟着老师一起思考

直播有互动，才有价值，你能体验到被教育的感觉

hashset底层哈希表 O（1）
treeset底层平衡二叉搜索树，都是O（logn）

为什么是还需要平衡二叉搜索树？
因为他是排好序的
你需要有序的关键字
找到这个元素或者比它小的元素
？这里再听一次
二叉搜索树中序遍历，升序

hashmap
treemap

空树也在二叉搜索树里
缺点是会退化，要维护，所以才是平衡二叉搜索树（AVL或者红黑树）


只记平均和O（1）
这些都是模板，滚瓜烂熟吧




算法找它的最近重复性
主要是前三个

循环，移动零，操作数组下标

二分法参考拉布拉东



最关键的掌握递归和模板

代码核心模板，有时间就看

生成图片，放到微信收藏起来



为什么不要人肉递归？因为人肉，无法并行展开！

异地多活？怎么解决？

投资哲学

过遍数比做新题更重要
做一题，得一题

你没有全学完，感觉什么都不会
你一旦全部学完，渐入佳境，就非常好了

基础性知识的难题，就能说出来就行，简单题中等题，必须会做

滴答清单，设置艾宾浩斯的曲线


过遍数你会感觉不一样
你会渐入佳境

LC 91 numcoding

看题解，先广搜再深搜
官方题解一般就很坑，为了KPI写的
秒懂，大神，这种一般比较好
自己把它简化

李永乐老师爬楼梯传送门

太深的，不要看，劝退不好
把自己能做的先做到位再说

逻辑思维能力能达到什么水平？
123级台阶爬楼梯？
上法打印


你可以不断变化，可以看人做到第几层，有梯度，就能知道面试者的水平
面试者很紧张，大部分都做不出来

你问一下身边的人，移动零的问题，会是一塌糊涂

会做，不会做，就是两个级别
基本功不过关，项目再怎么做都没有成长性

算法做好了，就有底气，哪家都可以去

牛顿迭代法，可以不用掌握

这些东西，看上去简单
但是从零到一会很难

你见到强的代码，应该狂喜，全部吸进来
记在脑图里
慢慢有自己的内功，核心竞争力了

存在lc里也挺好
聚类，一批题目一起学


考试：

分治法，子问题之间不包含公共的子问题
n皇后最坏时间复杂度
n的n次方都要搜一遍

但DFS是O多少的呢
循环队列 front 和rear

四数之和
跳跃游戏2

都做的不是很熟练


第六周：
第十二课：动态规划
第一部分：动态规划基础
分治
回溯
递归
动态规划

复杂问题分解为子问题，然后找它的重复性
【走了这么多年，终于到了这一步，我要全部学会】

递归

递归四步
#recursion terminator 递归终结条件    
#process logic in current level 处理当前层逻辑 
#drill down 下探到下一层   
# reverse the current level status if needed 恢复当前层状态
如果是参数，那就不需要恢复，递归调用时参数会被复制
如果是简单变量的话，就不需要恢复

【做题去理解这个过程】

分治

自相似性、重复性
大问题分解为子问题分别运算，结构重复，每步返回结果，最后聚合求解
# Python
def divide_conquer(problem, param1, param2, ...): 
  # recursion terminator 
  if problem is None: 
    print_result 
    return 
  # prepare data 
  data = prepare_data(problem) 
  subproblems = split_problem(problem, data) 
  # conquer subproblems 
  subresult1 = self.divide_conquer(subproblems[0], p1, ...) 
  subresult2 = self.divide_conquer(subproblems[1], p1, ...) 
  subresult3 = self.divide_conquer(subproblems[2], p1, ...) 
  …
  # process and generate the final result 
  result = process_result(subresult1, subresult2, subresult3, …)
    
  # revert the current level states
终止条件
拆分
调子问题的递归函数
结果合并


找到最近最简的方法，将其拆解成可重复解决的子问题

如果没有重复，一般也不会用算法，复杂度就在那里，也不会考
如果一开始很复杂，那么一定可以拆解成可重复解决的子问题
业务逻辑很复杂，那就只能硬写了

可重复问题——数学归纳法
本质：寻找重复性，用计算机本身的指令集解决（指令集本身很简单，优势是可以重复）
if else 递归
因为是简单指令集 RICS
（CICS复杂指令集）
（还需要到加法器那一节去学习）

人脑递归很慢，就算有递归树
为什么？因为每一层的状态个数是指数形式的
人力根本没办法展开

动态规划：分治+最优子结构

DP 动态递推

将复杂问题用一种递归的方式分解成简单的子问题
DP求最优解、最值、方式的总数
因为最优子结构存在，就节省了空间，不用保存每一步的状态，只需要保存每一步最优的状态

当然还需要证明算法最优值的传递性，能从每一步局部最优推到全局最优，最优状态是有一致性的

一：缓存、状态的存储数组
二：每一步淘汰次优状态，只保留最优/较优的状态（对推导到全局最优有影响力）

动态规划和递归或分治没有本质上的区别，关键看有无最优子结构
如果没有最优子结构，就需要计算每一步的中间结果，再求最后的结果，也就是传统的分治
动态规划是特殊的分治，加入了比较和淘汰中间结果，保留最优结果的过程

共性：找到重复的子问题
差异性：动态规划有最优子结构，中途可以淘汰次优解（也必须淘汰，这是降低算法复杂度的核心，变指数级为幂次级）

学会了，我真的学会了，再把题目练一练，就彻底学会了
一般看几重循环，实际执行次数就是n的多少次方，懂了

动态规划问题：可以递归，但是是指数级的

第二部分：实战题目解析

java三目运算符
条件 ？ansTrue ：ansFalse

代码简洁、逻辑清晰
right clean code


斐波那契数列
记忆化搜素后就是O(n)的复杂度，每个位置都仅被计算一遍
缺点是开了O（n）的额外空间，需要动态规划确定滚动数组影响范围，优化空间到常数级别
其实从下往上画记忆化搜素树，你会发现生长下一层只需要两个值，懂了

记忆化搜素并不等于动态规划的原因是记忆化搜素保存了每一个阶段的最优状态
而动态规划只会保存对后续结果有影响的阶段最优状态

 class Solution:
    def fib(self, n: int) -> int:
        if n <= 1: return n
        a = [0, 1]
        for i in range(n):
            a[i & 1] = (a[0] + a[1]) % (int)(1e9 + 7)
        return a[n & 1]
自底向上的方法，bottom up
递归树是从下往上生长的

而传统的递归到最后一层去结果
是自顶向下的，递归加记忆化搜素（递归）

自底向上是递推，写for循环

先递归分治，记忆化搜素，再化为自底向上的循环是没有问题的
（循序渐进）
但是竞赛一般都是直接自底向上写循环
只要递归，全部开始写for循环

这也是DP叫动态递推的原因
就是for循环，复杂度可控
记忆化搜素是不成熟的，可能StackOverflow或者超边界，复杂度未知


当维度变化为二维或者三维，加上取舍最优的子结构
题二：
路径计数

懂了，只有两个状态可以转移，向下或者向右
路径触达了某一个格子，就继承了这个格子之后的所有状态

子问题，从该点走向终点有几种可能

总的路径是从其他地方走向该点有几种可能 乘以 从该点走向重点有几种可能
把所有的中间量都加起来
先做没有障碍物的，再做有障碍物的

sum =f(start,end) = f(A,end ) + f(B,end)
只可能这两种子问题，再展开
两个参数，起点和终点

分治，找最近最简的重复性
其实就是斐波那契数组的二维形式，问题的本质是一样的
加了数组就变成记忆化搜索了
递归没有到达终止条件就不知道结果
这是自顶向下 的缺点

自底向上要稳定一些
递推形式：
懂了，是那种先搜索网格边界，再一步步累加算出上层结果的过程，data老师在黑板上讲过

任何一个点的走法是下面的点走法+右边的点的走法
边界继承
障碍物是0

DP方程、动态规划方程
状态转移方程是递推的关键，斐波那契是f(n) = f(n-1) + f(n - 2)

我懂了，当时能理解意思，但没有完全掌握，现在重学，彻底搞懂了要

if a[i,j]  空地:
opt[i,j] = opt[i+1,j] + opt[i, j+1]
else:
opt[i,j] = 0

状态转移方程是分类的
递推的初始值和逻辑是对的，答案就一定对
因为数学归纳法的逻辑性在这个问题的范围内是正确的

有什么情况下不能用数学归纳法？——皮亚诺公理
C++或java是非解释性语言，这个需要学编译原理来解决
掌握一门语言是在能查资料的情况下不会因为语法而卡住

四种动态规划的类型，树型动态规划，坐标型动态规划，区间型动态规划这样子


动态规划的本质就是数学归纳法，找重复性，加筛选过程优化，很规整
动态规划关键点
1.最优子结构
2.存储中间状态
3.递推公式（状态转移方程）
可能会加入最小值或者最大值的判断

简单DP：定义状态，把状态定义对了，且能有效存储，就能做出来
分治是把中间状态放在递归过程中了

  def countPaths(grid, row, col):
            if validSquare (grid, row, col): return 0
            if isAtEnd(grid, row, col): return 1
            return countPaths(grid, row + 1, col) + countPaths(grid, row, col + 1)

题三：最长公共子序列

一定要去阅读别人的代码，特别是高手的代码
这样你才有反馈，才有学习和成长
守望也一样，看高手的录像，同英雄同地图，看他怎么站位处理的，学习才有成长
自己要少打，多总结，多学习，和下象棋一样
学得差不多了，就进入疯狂练习的状态，能力上一个台阶，美滋滋

当它是字符串DP时，它不再是简单的字符串了，而是要扩展成二维数组来解决
之前简单的DP是它本身数组的结构，或者棋盘本身的二维数组结构就是你的状态空间

最长公共子序列：顺序要一致，中间可以跳字符
题目只需要输出长度

暴力都不太好想，所以是中等难度的题目，就是得多刷，花时间，过遍数，不然你花多少钱都不好使

暴力：
先枚举text1里的子序列，取或者不取，然后生成一个list
把这个list里的每一个元素去和text2比较，一个个找，不匹配就+1，结束后计算长度，存起来，拿一个max标志记录长度，最后的max就是最长的长度
时间复杂度是n*2^n

括号问题，左括号右括号


10月27日起

最长公共子序列

s1，可取可不取，遍历，然后进到右边去比较，2的n次方时间复杂度
s1长度为n
s2长度为m
暴力法的总时间复杂度 m*2^n

通过从后往前删减（其实从前往后一样，本质没差
从后往前是写递推公式，从前往后是计算方式，总之是同构的）
化简为子问题
字符串问题一般用二维数组来解决 
二维数组，行和列分别是两个字符串
就是
本质是比较两个字符串的相似度



数组里的数字表示行和列对应的两个子字符串间的最长公共子串的长度


自顶向下和自底向上两种方式嘛
自顶向下是递归+记忆化搜索
自底向上是递推公式，肯定是后者比较厉害嘛，因为双重循环的结果和消耗是确定性的，不会有性能上的限制嘛

递推公式并没有变，只是执行方向不一样了
————————
————
其实本质还是两条，这个是独立的，二维数组记录的只是当时的状态而已
动态规划的本质就是递推
你不用想懂二维数组的展开
你只要从含义出发

匹配
dp[i][j] = 1 + dp[i-1][j-1]

不匹配，看跳过哪个字符串的1位，代价最小
dp[i][j] = max(dp[i - 1][j],dp[i][j - 1])

这个递推方式是一步步推下来的
双重循环
二维矩阵是一层一层来填的

不存在圣杯，不会有更深的规律了，因为两种情况都有，都需要继承

还没想清楚，再看吧
懂基本意思了，但还没想透
子问题的子问题被包含了，所以从逻辑上考虑i-1和j-1就行了
有些关系是冗余的，被包含了的，不需要重复计算
-2被-1的子问题包含了，不需要一步考虑，只要层级间的递推关系逻辑没问题就行，类似数学归纳法

你要学数学的本质和科学的本质，投资的本质
这是比表面光鲜亮丽更重要的，也许去元气浓郁的地方能接触得更快，但关键还是看自己
资料太多了，时间都一样，足够自己学了

定义动态规划的状态，切分，找准子问题和递推方程
初窥门径，要学会了！

先完成再完美好吧，最后课程都没听是最亏的

就是要多练，多做，真的很简单，多练就自然会了，过遍数
边界条件，防止数组越界
这里从 1到n+1的理由是
本质是——
因为除了这些字符串本身，还有一个全部都不取的情况，也要考虑进来
当s1为空和s2匹配，s2为空和s1匹配
这个在计算两个字符串的匹配度的时候，用到的比较多

颜色就是笔记的模块化，颜色的本质是分类，清晰的美感
一些东西看似复杂，思维的本质是一样的，我能把迭代元认知写透，我的写作功底就到了
先记住细节，能自己实现了
再慢慢过遍数，优化，化繁为简，掌握本质
融会贯通，把书读薄

就像物理定律，虽然一开始有很多，但是学到最后，宏观世界就是相对论，微观世界就是量子力学，厉害了
最后还有一个弦理论


机器思维，是最简的if else goto，找重复性
你要变成算法思维，这是理解复杂逻辑的关键
把事情归约到重复性子问题上，计算机就可解了

职业进阶的要点，你最终要成为管理岗，管理岗的核心就是分治，分而治之，然后领导下属，给予指导和反馈
不用亲力亲为，不要微管理，让下面的人去管理就行了
你把你的直系带好，教会，他们自然会管好下面的人
教他们方法，给予反馈，允许犯错

MIT的教授也只是一个算法的初学者，不是职业竞赛级的那种，和FB的程序员没法比

MIT课程
https://www.bilibili.com/video/av53233912?from=search&seid=2847395688604491997
5 easy steps to DP 
定义子问题                        
猜子问题的解
合并子问题的解
递归和记忆化（自顶向下）/递推DP状态表（自底向上）
合并解决总问题

MIT的课程也没有优化到极致，水平不过如此，但是能学会是一定的，要和真正做到极致的高手学习，不要太迷信权威
你要知道那些没办法量化衡量水平的地方
可能那些大牌也没有那么厉害
当然大牌里厉害的是真的厉害
牌子是一种抽象，一种信用背书，一种参考，可以被更新的

先递归，再递推
两种方法来回多试几遍，理解本质，差不多就学会了
本质就是找重复性
化简为计算机的机器思维，if else goto能解决的（硬件约束是本质，底层基础决定上层建筑）


覃超三步DP：
化繁为简，分治找重复性和各种子问题（类似分类讨论，逻辑全）
定义好状态空间
记忆化搜索+递归/动态规划的方程（自底向上）递推

关键是练习这些题型，把题学会，反思掌握思想，其实真不难

实战讲解
爬楼梯，扩展

1 2 3 三种走法怎么解 (ez)
三类就行了
f(n)= f(n-1) + f(n-2) + f(n-3)

相邻步伐不能相同，怎么解 (medium)
枚举法呗
还是分类
找最大不同步数的循环
分类成子问题，再分类成子问题

放弃人肉递归？
1——1
2——2
3——12，21，3
————上面是基石，后面都是重复
f(5)=f(1) + f(4) + f(3) + f(2)
懂了，f一个数，表示已经走出这一步了，还需要多少走法
其实一维解决不了问题的
应该加入一维
就是上一步是什么走法？1，2还是，3

4——121，13，31
5——

如果你想自己推if else的逻辑，就越来越复杂了
你只要掌握最简单的基本逻辑的组合就行了
后面都是重复性的内容

f(n)(*)= f(n-1)(1) + f(n-2)(2) + f(n-3)(3)
f(i)(1) = f(i - 2)(2)+f(i-3)(3)
f(i)(2) = f(i - 1)(1) +f(i - 3) (3)
f(i)(3) = f(i -1)(1) + f(i - 2)(2)

解决了，这算我又刷了一道题，关键是问题想清楚了
统计刷题具体量没什么意义，还是在LC上看吧，没有落实到LC的都别算，差别不大的，有个概念就行了
锻炼自己的算法思维
二维数组DP，第二个维度是上一次走的方式, 滚动数组循环
走了123中的一步，下一个子问题就是除了它这一步外，其他两种情况的累加
初始化后
for i in range(2, n):
    for j in range(3):
        f[i][j] = f[i - (j) % 3][(j - 1) % 3] + f[i - (j - 1) % 3][(j - 2) % 3]
return f[n-1][0] + f[n-2][1] + f[n-3][2]


线段树也不会啊
学什么？怎么学？

动态规划的核心就是找准子问题，戒掉人肉递归的习惯
你不需要人肉分出逻辑
你只需要交给计算机数学归纳法的递推公式就行

a[i] + dp[i - 1], a[i]
他会自动舍弃掉起到副作用的序列段


杨辉三角，三角形数组这些题能用动态规划的原因是——重复性
找到了！
暴力求解，每次往左或者往右，一定存在重复性
动态规划的目的是一次遍历解决问题，每个阶段保留最优结果，不进行重复计算
时间复杂度才会优化

1 找重复性
2 定义OPT状态数组，是1维还是2维的（基本就这两种）
3 DP状态转移方程

这个和不同路径的问题，是异曲同工的，只是它是数量和，这里是求路径权值和

到达上层点的路径和就是下层两个路径中的最小者+上层点本身的值

懂了
dp =triangle这种赋值有点巧妙哈
虽然费了额外的空间，但是省事，机器不爽我舒服
工业级代码一般不能直接改源数据，因为万一程序出错，你要重跑，源数据已经变了啊
没有重复使用性

写代码注释，要把副作用给讲明白
side effect: 修改原数组内容/redis修改不可回退
java取数组值时要.get().get()
有那种严格的面向对象编程的意思

递归要写一个helper子函数把参数都传进去

递归优化就是记忆化搜索
加一个cache，把参数传进去，就是i，j和结果关联起来，遇到对应的i和j就不重复计算了
if memo[i][j] != None:
    return memo[i][j]

在python里是add LRU_cache

DP核心：
状态数组一维还是二维
方向自顶向下还是自底向上
状态转移方程的逻辑是否复杂，复杂可能就不是最优形式
边界条件的判断，会不会超界或者冗余？

简洁程度和复杂度都是最好的，那么写起来轻松，代码漂亮，你的面试成绩一定是最好的
所以要多练


连续子数组的最大和/积

人肉递归的危险就在于从数学上来说不严谨，可能会有人没有考虑的地方，也可能不具有递推性和普适性
在逻辑上也很难找到它的自相似性

拿捏火候靠经验的解决方法，在用计算机解决问题时是要杜绝的
一切都是程序化，逻辑严密的
一定要转换成机器思维，程序化后就对同类问题的解决有可重复性，可复用，就变成一条规律了
变成本质的东西了
学习，学的不是知识，知识百科里都有
学习，学的是问题的场景，和解决对应问题的模块和规律本质的理解
懂了懂了
在投资，炒币，工作时，也有一样的误区
大概看一下，凭感觉，好像可以，这种，是永远做不好投资的

找到自相似的，有重复性的方法，化繁为简
做透一类问题，这才是关键
复杂事情简单化，简单事情重复做

同时逻辑上是简洁的
且能够严谨的证明
这就是能成功的可靠方法

程序化思维，是可重复做好任何事情的关键
可以去思考一下它背后的规律



超哥期末直播

map查找复杂度
hash O(1) 
tree，bst有序 O(logn）

https://shimo.im/folder/WjP9V3HWpJYhCTKr



把面试当做和未来同事沟通的场景，信任，有安全感，沟通、交流

期中之后的高级数据结构

trie
我已经掌握这部分算法了
确实，这个课程我最该学的就是动态规划
全部学完了就可以开始做周赛了，定期刷题了，自己慢慢进步了，蛮好


插入的时候不断往后找单词所在的child，没有就插进去


java实现，明显更复杂了


用数组记录节点

中文怎么存trie
中文是基于字的，周杰伦，周杰，周
理论上可以展开的有几千种

字典序就行了

在后面就更少了
基于词组的前缀树，用频次表示谁更加优先这样

并查集
根节点 parent[i] = i





并查集解决的问题：谁和谁是一类

布隆过滤器



如果被设置为1，可能存在
如果没有被设置为1，肯定不存在

这就是布隆过滤器

哈希里去找，理解的是对的

其实只记录它在或者不在
无法记录具体内容，无法反向寻找
内容存在数据库、内存里（哈希里）

数据结构的本质，大规模分布式系统里，先找它是否存在，再去查找具体的它
查询机器之前，先看是否在这个分区，如果不是，那么肯定不需要找，看能否查到，增加了一层效率的优化

LRU cache


哈希表和双链表去做

LRU只是替换算法，替换算法有很多，LRU、LFU
LRU都是O(1)的
实现的代码


位运算



位运算时，要考虑无符号整数和有符号整数吗？
算术性质要考虑

只利用位的性质，不需要考虑，看你具体操作的目的对符号是否敏感
你取n位置为1，管你符号干嘛

关键还是计算机基础要扎实

-1的二进制

11111111



位运算是优化代码质量，简化代码操作的奇招


X & （X - 1）清零最低位的1
X & -X 得到最低位的1
X & ~X + 1保留最后一位1
位运算主要的目的是检查位有没有被用过


高级二叉搜索树
2-3树，AVL、红黑树等等

串讲算法：递归、分治、回溯、动态规划

肌肉式记忆，不然前功尽弃




没有重复性，那也没必要用算法了，计算机无能为力了
能用计算机解决的，都有重复性，因为计算机体系结构这么决定的
唯一的优势就是重复运算比人快

没有重复性也没必要分治
没有重复性也用不上算法了

子问题内在有联系，有重复性，所以能用分治

新一代的深度学习本身
信噪比特别高
如何找规律？全部送进神经网络，它自己去找中间的规律
万事万物是不是有规律的呢
物理上来看，现在是的
牛顿，相对论，量子力学
找到规律后，就很简单了

人是人类new出来的一个对象
人类也是一个类，父类是哺乳动物
鸟类也继承了哺乳动物的性质

寻求需求，有很多API是通用的，马斯洛需求效应

怎么看的
怎么设计的这些规律
就很深刻了，规律是被更高级的存在设计出来的吗？不知道啊
但是我想去学，加油，我觉得算法这块我是问题不大了，再刷题就行

elon musk 也许我们在模拟器
也许我们是放在营养球上了
像细菌培养皿一样

多了嵌套和思考后，会忘记中间的状态，这就是人类为什么不擅长人肉递归的原因

爬楼梯
还有一个什么问题？
括号生成问题
硬币兑换问题


动态规划：基于分治的，解决重复性问题，但是动归有最优子结构，可以保存起来

具备最优子结构，就可以动态规划加速，否则老老实实分治

动态规划可以自底向上递推——动态递推
打家劫舍没有淘汰掉中间过程，没有把最优值向上传递，那也不叫动态规划


只用两个是因为python可以两项同时赋值

把状态分类，然后定义转移过程——DP状态转移方程
难者不会，会者不难
我会了，自然就不难了

LC 64 最小路径和
LC 120 三角路径和
兄弟问题

如果不自己动手做，那么学习算法训练营就没有意义了
Java也是一样

掌握逻辑化的做事方法，具有扩展性，才能有希望解决这一类的全部问题
而不是靠想，靠灵感
看的是方法

习惯化解为子问题
再把子问题的思路理清楚
这样无论怎么follow up你都会

打家劫舍，如果有负的，你怎么偷

没必要化成最简式
化成最适合人逻辑理解的形式就行了，可读性
这一块是干嘛的，要理解

再扩展

a[i - 2] + nums[i] ，就肯定可以偷
a[i - 1] 是不偷 i
然后为什么在前面放a[ i- 2]呢，因为被 a[i - 1]包含了，至少不会比a[i - 1]大

状态冗余，是理解不到位
是因为没有优化好

递推和子问题分类的方式，遇到怎么样的问题都可以变化求解
而人脑找规律，和人肉递归一样，不靠谱，不能扩展

股票买卖

过高频题

LC 2 两数相加

75 颜色分类问题
排序，计数，双下标



去重，去掉一个数组里的重复元素
229， 169求众数，和去重互为相反问题，一样的解决

239
滑动窗口，双端队列
有序的就是单调队列


前面差一题
三数之和，四数之和（多加一重循环，到size - 3 就好，还需要三个元素给内层，到顶了）
双指针夹逼求sum

24 两两兑换链表
10.01面试题  合并两个有序数组——从后往前做


21合并两个有序链表



23 合并k个链表
多路归并，一般前面面得不错，才会遇到这题，是机遇也是挑战
1暴力
2归并排序
3优先队列（堆） 头结点放进去，不断更新
字节跳动三面压轴题

104数的最大深度


102层次遍历
BFS、DFS，都可以写
O（1）时间打模板出来

46全排列 递归回溯法

什么时候要回复？看它是复制出来还是就在里面修改
如果你拷贝了一份，就不用回复

关键是参数的作用域，这是代码掌控力的部分

副本里的count和之前的count是不一样的，局部变量在子函数里不能影响外面啊，作用域有限

LC 22 
可以用BFS吗？
可以，因为反正是生成树嘛

再把DFS，BFS解决

127单词接龙


逻辑上和python没什么区别


200岛屿数量问题
岛屿是4联通的
岛屿数量，5分钟要秒杀全解
写不完，一定要多练
因为这是第一步基础
基于它才会有扩展，不然你后面搜索题全不会
过不了二面和三面




79单词搜索
代码量很大
但和岛屿问题没什么差别

LC 84 直方图求最大面积
单调栈（一定要学会）

42接雨水
这两个问题一起做

动态规划高频题在高级动态规划里讲过了


答疑

最优解打印路径，怎么做呢？
就是你在每一个状态时新开一个数组，放一个steps
表示具体的方案
steps在dp的每一步都记录它之前的位置
最后把steps输出就行了

本质上不是看你努不努力啊，就是要学的东西还有很多
你就这样松懈，放弃，岂不是完蛋了

记录路径，记录DP状态转移时的路径，是从哪个下标位置过来的
最后打印三角里的值就行了



再就是res 数组每次 + 这个下标对 tuple（类似与数组后面加了元素这样，把数组最后依次打印，就是路径了）

打印所有的方案：

直接DFS，把所有方案递归出来
LC 70 爬楼梯


老的题目，测试数据加了很多，或者接口更新了，就不太好学了，不要纠结它的问题
更新即可


要学的东西太多了，就把公司要的技术栈用脑图总结出来

现有代码的业务逻辑
过遍数
学习，总结成体系



资本永不眠

基本功练熟

这是思维习惯

过一遍的知识点，考前背一背，讲讲原理就行了
链表的题目就是熟练度，写漂亮，不过脑子就行了，切忌现场推

人的大脑就是容易忘记，就是要周期性反复过遍数，不断激活这些知识点
后面会有复利效应，过了20遍，后10遍比前10遍更快，但是效果更多
你越来越掌握了，激发出对其本质的理解，能够迅速复现，你就大彻大悟了
越读越厚，越读越薄，最后就融会贯通了

校招算法更偏重，社招更偏重项目细节和一些性能优化等
社招会有工业级别项目的问题，你要理解深刻



期末考试
这不是结束，甚至不是结束的开始
后面的路还很长，钥匙给到我手里，自己努力去做吧

原来不知不觉已经过了这么久，原来每一次考试都来不及准备好就结束，原来我们的相遇是如此的匆匆。希望我们大家在未来的路上越走越好吧，一起加油。

